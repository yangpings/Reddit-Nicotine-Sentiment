{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 2 Analysis",
   "id": "ddf6b86503c07a0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### NEED TO BE IN PYTHON 3.9 ENV FOR spacy TO WORK!!!! \n",
    "\n",
    " #Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#import string\n",
    "from nltk.stem.porter import PorterStemmer"
   ],
   "id": "638b573cb8b8dfbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "general_log = pd.read_csv('reddit_post_comment_log.csv', index=False)"
   ],
   "id": "ce3333f4440056ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " initial count of keywords",
   "id": "51b98aae9915a1b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "value_counts = general_log['keyword'].value_counts()\n",
    "print(value_counts)"
   ],
   "id": "22d32b2502203675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "pie chart",
   "id": "edc541cc876f3978"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data provided\n",
    "keywords = ['rogue pouches', 'on! pouches', 'zyn', 'nicotine pouches', 'Lucy pouches', \n",
    "            'nic pouches', 'fre pouches', 'velo pouches', 'niin pouches', 'fr3sh pouches']\n",
    "counts = [9094, 8253, 7304, 4871, 2963, 2180, 1642, 1391, 88, 11]\n",
    "percentages = [count / sum(counts) * 100 for count in counts]\n",
    "# Creating the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(counts, labels=keywords, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
    "\n",
    "# Customize font\n",
    "plt.title(\"Distribution of Pouches by Keyword\", fontsize=16, fontweight='bold', family='serif')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Set the font properties for the labels\n",
    "plt.setp(plt.gca().texts, fontname='spectral', fontsize=11, fontweight='normal')\n",
    "\n",
    "plt.show()"
   ],
   "id": "7b04c1a1e24b84ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## text cleaning and lemmatization/tokenization",
   "id": "32ec66a2557a93a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "general_log[\"post\"] = general_log[\"post\"].str.lower()\n",
    "general_log[\"post\"] = general_log[\"post\"].replace(r'\\?', '.', regex=True)\n",
    "general_log.head()"
   ],
   "id": "a21b0abc6236354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ],
   "id": "738e93f338c8c7df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "'''\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "'''\n",
    "additional = [\"nan\", \"else\", \"know\", \"take\", \"still\", \"seem\", \"mg\", \"go\", \"ago\",\"maybe\", \"always\", \"put\",\"thing\",\"use\",\"get\",\"much\", \"www\", \"reddit\", \"moderator\", \"message\", \"https\", \"even\", \"lol\", \"com\", \"bot\", \"subreddit\", \"people\", \"delete\", \"sure\", \"really\", \"telegram\", \"askwoman\", \"comment\",\"fuck\",\"shit\",\"literally\",\"every_day\",\"fucking\",\"let\",\"stuff\",\"also\", \"com\", \"really\", \"https_www\" ]\n",
    "#nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english') + additional"
   ],
   "id": "1c9c730f92c88e1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in doc if word not in stop_words] for doc in texts]"
   ],
   "id": "ce2d31d3c9d416b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV','PROPN']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ],
   "id": "1a6e357ac3b7b170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize_lemmatization (text):\n",
    "    data_words = list(sent_to_words(text))\n",
    "    remove_stopwords_words = remove_stopwords(data_words)\n",
    "    print(\"done_tokneize\")\n",
    "    bigram = gensim.models.Phrases(remove_stopwords_words, min_count=30, threshold=10) # higher threshold fewer phrases.\n",
    "    #trigram = gensim.models.Phrases(bigram[data_words], threshold=50) \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    #trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    print(\"done_bigram\")\n",
    "    bigram_text = [bigram_mod[doc] for doc in remove_stopwords_words]\n",
    "    \n",
    "    \n",
    "    data_lemmatized = lemmatization(bigram_text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV','PROPN'])\n",
    "    # remove stopwords again\n",
    "    remove_stopwords_words = remove_stopwords(data_lemmatized)\n",
    "    \n",
    "    return remove_stopwords_words"
   ],
   "id": "af99b8dafc60e14d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log",
   "id": "3fec5b62f69eef32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selected_text = general_log[\"post\"]\n",
    "clean_text = tokenize_lemmatization(selected_text)\n",
    "clean_text "
   ],
   "id": "53d7925f235bb756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentiment Analysis",
   "id": "6d21771787d3b135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer",
   "id": "cc1a063580ef4eaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sentiment_scores(sentence):\n",
    " \n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # object gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    compound = sentiment_dict['compound']\n",
    "    neg = sentiment_dict['neg']\n",
    "    pos = sentiment_dict['pos']\n",
    "    neu = sentiment_dict['neu']\n",
    "    \n",
    "    return compound, neg, pos,neu"
   ],
   "id": "cbc35041feb67aea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " positive when score >0.05 , neutral when score <0.05 and >-0.05 , negative when <-0.05",
   "id": "89425de9dc3dbaf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "compounds = []\n",
    "negs = []\n",
    "pos_ = []\n",
    "neus = []\n",
    "i = 0\n",
    "for i in range (len(selected_text)):\n",
    "    if selected_text[i] is None or (isinstance(selected_text[i], float) and selected_text[i] != selected_text[i]):\n",
    "        compounds.append(float('nan'))\n",
    "        negs.append(float('nan'))\n",
    "        pos_.append(float('nan'))\n",
    "        neus.append(float('nan'))\n",
    "    else:\n",
    "        compound, neg, pos,neu  = sentiment_scores(selected_text[i])\n",
    "        compounds.append(compound)\n",
    "        negs.append(neg)\n",
    "        pos_.append(pos)\n",
    "        neus.append(neu)\n",
    "        \n",
    "general_log[\"compounds_score\"] = compounds\n",
    "general_log['pos_score'] = pos_\n",
    "general_log['neu_score'] = neus\n",
    "general_log['neg_score'] = negs\n",
    "#categorize scores as neutral, positive, or negative\n",
    "conditions = [\n",
    "    (general_log['compounds_score'] <= -.05),\n",
    "    (general_log['compounds_score'] > -.05) & (general_log['compounds_score'] < .05),\n",
    "    (general_log['compounds_score'] >= .05)\n",
    "]\n",
    "\n",
    "values = ['negative', 'neutral', 'positive']\n",
    "\n",
    "general_log['post_group'] = np.select(conditions, values)\n",
    "\n",
    "general_log.head()"
   ],
   "id": "d1fd7703f5a11cd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log",
   "id": "72e9a31475e32c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log.to_csv('reddit_combined_with_vader.csv', index=False)",
   "id": "2189b78bcd92ae8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log = pd.read_csv('reddit_combined_with_vader.csv')",
   "id": "deb01d80e523e388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#mean sentiment score\n",
    "mean_sent = np.mean(general_log['compounds_score'])\n",
    "print(\"Mean Sentiment Score is:\", mean_sent)\n",
    "\n",
    "#proportion neutral\n",
    "prop_neut = len(general_log[general_log['post_group']=='neutral'])/len(general_log)\n",
    "num_neut = len(general_log[general_log['post_group']=='neutral'])\n",
    "print(\"Proportion neutral:\", prop_neut)\n",
    "print(\"Number neutral is:\", num_neut )\n",
    "\n",
    "#proportion positive\n",
    "prop_pos =len(general_log[general_log['post_group']=='positive'])/len(general_log)\n",
    "num_pos = len(general_log[general_log['post_group']=='positive']) \n",
    "print(\"Proportion positive:\", prop_pos)\n",
    "print(\"Number positive is:\", num_pos)\n",
    "\n",
    "#proportion negative\n",
    "prop_neg =len(general_log[general_log['post_group']=='negative'])/len(general_log)\n",
    "num_neg = len(general_log[general_log['post_group']=='negative'])\n",
    "print(\"Proportion negative:\", prop_neg)\n",
    "print(\"Number negative is:\",num_neg )\n",
    "print(f\"The sum of all posts n = {len(general_log)}\")"
   ],
   "id": "5e277345d0da8ce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### sentiment histogram ",
   "id": "1e4f168758ab267a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "proportion of three categories",
   "id": "96e7dfb4eae4cfc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Data for plotting\n",
    "categories = [f\"Overall Posts (n = {len(general_log)})\"]\n",
    "scores_1 = [prop_pos]\n",
    "scores_2 = [prop_neut]\n",
    "scores_3 = [prop_neg]\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 0.2\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "bar_positions_1 = np.arange(len(categories))\n",
    "bar_positions_2 = bar_positions_1 + bar_width\n",
    "bar_positions_3 = bar_positions_2 + bar_width\n",
    "\n",
    "# Create the bar chart\n",
    "plt.bar(bar_positions_1, scores_1, width=bar_width, color='orange', label='Prop Positive')\n",
    "plt.bar(bar_positions_2, scores_2, width=bar_width, color='lightgreen', label='Prop Neutral')\n",
    "plt.bar(bar_positions_3, scores_3, width=bar_width, color='lightblue', label='Prop Negative')\n",
    "\n",
    "# Set x-axis tick labels and title\n",
    "plt.xticks(bar_positions_2, categories)\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Proportion of Sentiment for All Posts.')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "e599e25332970244",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "proportion of overall compound scores",
   "id": "50a5ab35b4605af7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute mean\n",
    "compound = general_log[\"compounds_score\"]\n",
    "mean_score = np.mean(compound)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(compound, bins=20, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add mean as a vertical black dashed line\n",
    "plt.axvline(mean_score, color='black', linestyle='dashed', linewidth=2, label=f'Mean: {mean_score:.2f}')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('VADER Sentiment Compound Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Sentiment of Overall Posts (n = {len(general_log)})')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ],
   "id": "75746f50b4f4a396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "revisting the distribution",
   "id": "8026ca9cb148d165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LDA",
   "id": "e179136f9bd3a266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "clean_text",
   "id": "2e918db380081cb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create Dictionary\n",
    "id2word_train = corpora.Dictionary(clean_text)\n",
    "id2word_train.filter_extremes(no_below=4, no_above=0.95)\n",
    "\n",
    "# Create Corpus\n",
    "texts_a = clean_text\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word_train.doc2bow(text) for text in texts_a]\n",
    "print(f\"Dictionary size: {len(id2word_train)}\")\n",
    "print(f\"Corpus size: {len(corpus)}\")"
   ],
   "id": "b1369b94f2e46370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "id2word_train.save(\"corpora\")\n",
    "id2word_train=corpora.Dictionary.load(\"corpora\")"
   ],
   "id": "274219ef05e7c1d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "# coherence value\n",
    "start_time = time.time()\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "for num_topics in range(2, 14):\n",
    "    model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word_train,chunksize=50,\n",
    "                                           random_state=100)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    model_list.append(model)\n",
    "    coherencemodel = CoherenceModel(model=model, texts=texts_a, dictionary=id2word_train, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())\n",
    "    print(num_topics)"
   ],
   "id": "fffa20901be69501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "coherence_values",
   "id": "2ec52f6abb565a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "id": "770bd0810aed413e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(model_list[1], corpus, id2word_train)\n",
    "pyLDAvis.display(vis)"
   ],
   "id": "877db738b18f5b0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topic_coords = vis.topic_coordinates\n",
    "print(topic_coords)\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(topic_coords['x'], topic_coords['y'], c='b', alpha=0.5)\n",
    "ax.set_xlim([-0.4, 0.4])  # Adjust x-axis limits\n",
    "ax.set_ylim([-0.4, 0.4])  # Adjust y-axis limits\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Inter-Topic Distance Map')\n",
    "\n",
    "# Add topic labels\n",
    "for i, (x, y) in enumerate(zip(topic_coords['x'], topic_coords['y'])):\n",
    "    ax.text(x, y, f'Topic {i}', fontsize=8, ha='center', va='center')\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "e2151698f39527af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Look at probabilities of top 20 words in each topic\n",
    "model_list[1].print_topics(num_topics = 3, num_words = 20)"
   ],
   "id": "b3e8306b530f68e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get topic coordinates and sizes\n",
    "topic_coords = vis.topic_coordinates\n",
    "topic_sizes = vis.topic_info['Freq']  # Assuming 'Freq' represents the sizes\n",
    "\n",
    "# Normalize topic sizes\n",
    "topic_sizes_norm = (topic_sizes - topic_sizes.min()) / (topic_sizes.max() - topic_sizes.min())\n",
    "\n",
    "# Create scatter plot with zoom and adjusted sizes\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "scatter = ax.scatter(topic_coords['x'], topic_coords['y'], c='b', alpha=0.5)  # Create scatter plot\n",
    "ax.set_xlim([-0.6, 0.6])  # Adjust x-axis limits for zoom\n",
    "ax.set_ylim([-0.6, 0.6])  # Adjust y-axis limits for zoom\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Inter-Topic Distance Map for Overall Posts')\n",
    "\n",
    "# Add topic labels\n",
    "for i, (x, y) in enumerate(zip(topic_coords['x'], topic_coords['y'])):\n",
    "    ax.text(x, y, f'Topic {i+1}', fontsize=8, ha='center', va='center')\n",
    "\n",
    "# Adjust circle sizes\n",
    "scatter.set_sizes(topic_sizes_norm * 10000)  # Adjust size scaling as needed\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "c79c0dd461b3059e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a word cloud for each topic where words that have higher probabilities are larger\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "WordCloud = WordCloud(background_color=\"white\",contour_width=3)\n",
    "for t in range(model_list[1].num_topics):\n",
    "    plt.figure()\n",
    "    words =  model_list[1].show_topic(t, 100)\n",
    "    words = dict((x,y) for x, y in words)\n",
    "    plt.imshow(WordCloud.fit_words(words))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Post Topic #\" + str(t+1))\n",
    "    plt.show()"
   ],
   "id": "edaed8e7efca087e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topics = []\n",
    "prob = []\n",
    "\n",
    "for d in clean_text:\n",
    "    bow = id2word_train.doc2bow(d)\n",
    "    probs = model_list[1].get_document_topics(bow)\n",
    "    max_prob = max([set[1] for set in probs])\n",
    "    prob.append(max_prob)\n",
    "    topics.append([set[0] for set in probs if set[1] == max_prob])\n",
    "\n",
    "# Truncate topics list if needed\n",
    "topics = topics[:len(general_log)]\n",
    "\n",
    "# Assign to DataFrame\n",
    "general_log[\"topics\"] = [t[0] if len(t) > 0 else None for t in topics]\n",
    "general_log[\"prob\"] = prob\n",
    "\n",
    "# Plot KDE for each topic\n",
    "for i in range(3):\n",
    "    general_log[general_log[\"topics\"] == i][\"prob\"].plot(kind='kde', label=f\"Topic {i+1}\")\n",
    "\n",
    "# Add legend, labels, title\n",
    "plt.legend(title=\"Topics\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"KDE of Probability by Topic\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ],
   "id": "43fb4eeb78bb1196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "while i < len(general_log):\n",
    "    if general_log.at[i, \"keyword\"] == 'nicotine pouches' or general_log.at[i, \"keyword\"] == 'nic pouches' :\n",
    "        post_text = general_log.at[i, 'post']\n",
    "        if 'velo' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'velo pouches'\n",
    "        elif 'zyn' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'zyn'\n",
    "        elif 'fr3sh' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'fr3sh pouches'\n",
    "        elif 'niin' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'niin pouches'\n",
    "        elif 'on' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'on! pouches'\n",
    "        elif 'rogue' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'rogue pouches'\n",
    "        elif 'fre' in post_text:\n",
    "            general_log.at[i, 'keyword'] = 'fre pouches'\n",
    "    if general_log.at[i, \"keyword\"] == 'on pouches':\n",
    "        general_log.at[i, 'keyword'] = 'on! pouches'\n",
    "    if general_log.at[i, \"keyword\"] == 'nicotine pouches' or general_log.at[i, \"keyword\"] == 'nic pouches' :\n",
    "        general_log.at[i, 'keyword'] = 'unspecified'\n",
    "    i += 1\n"
   ],
   "id": "7446b46e8b4702ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log",
   "id": "2f4bc0607d69ee1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "value_counts = general_log['keyword'].value_counts()\n",
    "print(value_counts)"
   ],
   "id": "1c472516b41690f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## sentiment by LDA",
   "id": "81917173934a9216"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#For easy understanding let's number the topics as 1,2,3 instead of 0,1,2\n",
    "general_log['topic_final'] = general_log['topics']+1\n",
    "print(general_log['topic_final'].value_counts())\n",
    "\n",
    "#check that this worked\n",
    "count_topic1 = pd.DataFrame(general_log['topic_final'].value_counts()).iloc[0][0]\n",
    "count_topic2 = pd.DataFrame(general_log['topic_final'].value_counts()).iloc[2][0]\n",
    "count_topic3 = pd.DataFrame(general_log['topic_final'].value_counts()).iloc[1][0]\n",
    "#also check the propotion for each topic\n",
    "print(\"Topic 1 count: n=\", count_topic1, \"prop = \", count_topic1/len(general_log))\n",
    "print(\"Topic 2 count: n=\", count_topic2, \"prop = \", count_topic2/len(general_log))\n",
    "print(\"Topic 3 count: n=\", count_topic3, \"prop = \", count_topic3/len(general_log))"
   ],
   "id": "499db08fad39d604",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#get just topic 1\n",
    "topic1 = general_log[general_log['topic_final']==1]\n",
    "\n",
    "#mean sentiment score\n",
    "mean_sent1 = np.mean(topic1['compounds_score'])\n",
    "print(\"Mean Sentiment Score is:\", mean_sent1)\n",
    "\n",
    "#proportion neutral\n",
    "num_neut1 = len(topic1[topic1['post_group']=='neutral'])\n",
    "prop_neut1 = len(topic1[topic1['post_group']=='neutral'])/len(topic1)\n",
    "print(\"Proportion neutral:\", prop_neut1, \"n:\", num_neut1)\n",
    "\n",
    "#proportion positive\n",
    "num_pos1 =len(topic1[topic1['post_group']=='positive'])\n",
    "prop_pos1 =len(topic1[topic1['post_group']=='positive'])/len(topic1)\n",
    "print(\"Proportion positive:\", prop_pos1, \"n:\", num_pos1)\n",
    "\n",
    "#proportion negative\n",
    "num_neg1 =len(topic1[topic1['post_group']=='negative'])\n",
    "prop_neg1 =len(topic1[topic1['post_group']=='negative'])/len(topic1)\n",
    "print(\"Proportion negative:\", prop_neg1, \"n:\", num_neg1)"
   ],
   "id": "2ea446eb70bd42ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#get just topic 2\n",
    "topic2 = general_log[general_log['topic_final']==2]\n",
    "\n",
    "#mean sentiment score\n",
    "mean_sent2 = np.mean(topic2['compounds_score'])\n",
    "print(\"Mean Sentiment Score is:\", mean_sent2)\n",
    "\n",
    "#proportion neutral\n",
    "num_neut2 = len(topic2[topic2['post_group']=='neutral'])\n",
    "prop_neut2 = len(topic2[topic2['post_group']=='neutral'])/len(topic2)\n",
    "print(\"Proportion neutral:\", prop_neut2, \"n:\", num_neut2)\n",
    "\n",
    "#proportion positive\n",
    "num_pos2 =len(topic2[topic2['post_group']=='positive'])\n",
    "prop_pos2 =len(topic2[topic2['post_group']=='positive'])/len(topic2)\n",
    "print(\"Proportion positive:\", prop_pos2, \"n:\", num_pos2)\n",
    "\n",
    "#proportion negative\n",
    "num_neg2 =len(topic2[topic2['post_group']=='negative'])\n",
    "prop_neg2 =len(topic2[topic2['post_group']=='negative'])/len(topic2)\n",
    "print(\"Proportion negative:\", prop_neg2, \"n:\", num_neg2)"
   ],
   "id": "cbfd802a92815f2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#get just topic 3\n",
    "topic3 = general_log[general_log['topic_final']==3]\n",
    "\n",
    "#mean sentiment score\n",
    "mean_sent3 = np.mean(topic3['compounds_score'])\n",
    "print(\"Mean Sentiment Score is:\", mean_sent3)\n",
    "\n",
    "#proportion neutral\n",
    "num_neut3 = len(topic3[topic3['post_group']=='neutral'])\n",
    "prop_neut3 = len(topic3[topic3['post_group']=='neutral'])/len(topic3)\n",
    "print(\"Proportion neutral:\", prop_neut3, \"n:\", num_neut3)\n",
    "\n",
    "#proportion positive\n",
    "num_pos3 =len(topic3[topic3['post_group']=='positive'])\n",
    "prop_pos3 =len(topic3[topic3['post_group']=='positive'])/len(topic3)\n",
    "print(\"Proportion positive:\", prop_pos3, \"n:\", num_pos3)\n",
    "\n",
    "#proportion negative\n",
    "num_neg3 =len(topic3[topic3['post_group']=='negative'])\n",
    "prop_neg3 =len(topic3[topic3['post_group']=='negative'])/len(topic3)\n",
    "print(\"Proportion negative:\", prop_neg3, \"n:\", num_neg3)"
   ],
   "id": "41ccee986c10899",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "general_log_topics_stat = pd.DataFrame(\n",
    "    {'topic_number': [1, 2, 3],\n",
    "        'mean_sent_score': [mean_sent1, mean_sent2, mean_sent3],\n",
    "        'prop_neutral': [prop_neut1, prop_neut2, prop_neut3],\n",
    "        'prop_positive': [prop_pos1, prop_pos2, prop_pos3],\n",
    "        'prop_negative': [prop_neg1, prop_neg2, prop_neg3]}\n",
    ")\n",
    "\n",
    "general_log_topics_stat"
   ],
   "id": "d411234952c0c004",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for three categories and their scores\n",
    "categories = general_log_topics_stat['topic_number']\n",
    "scores_1 = [prop_pos1, prop_pos2, prop_pos3]\n",
    "scores_2 = [prop_neut1, prop_neut2,prop_neut3]\n",
    "scores_3 = [prop_neg1, prop_neg2,prop_neg3]\n",
    "\n",
    "# Width of each bar\n",
    "bar_width = 0.2\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "bar_positions_1 = np.arange(len(categories))\n",
    "bar_positions_2 = bar_positions_1 + bar_width\n",
    "bar_positions_3 = bar_positions_2 + bar_width\n",
    "\n",
    "# Create the bar chart\n",
    "plt.bar(bar_positions_1, scores_1, width=bar_width, color='orange', label='Prop Positive')\n",
    "plt.bar(bar_positions_2, scores_2, width=bar_width, color='lightgreen', label='Prop Neutral')\n",
    "plt.bar(bar_positions_3, scores_3, width=bar_width, color='lightblue', label='Prop Negative')\n",
    "\n",
    "# Set x-axis tick labels and title\n",
    "plt.xticks(bar_positions_2, categories)\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Proportion of each Sentiment by Topic')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "id": "90b227efc38d5581",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "histogram of sentiment by topic",
   "id": "ed3066dea0949d8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define colors for each topic\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Loop through each topic (1, 2, 3)\n",
    "for idx, topic in enumerate([1, 2, 3]):\n",
    "    # Filter data for each topic\n",
    "    compound_topic = general_log[general_log[\"topic_final\"] == topic][\"compounds_score\"].dropna()\n",
    "    \n",
    "    # Compute mean sentiment score\n",
    "    mean_score = np.mean(compound_topic)\n",
    "    \n",
    "    # Plot histogram with a different color for each topic\n",
    "    plt.hist(compound_topic, bins=20, edgecolor='black', alpha=0.7, color=colors[idx])\n",
    "    \n",
    "    # Add mean as a vertical black dashed line\n",
    "    plt.axvline(mean_score, color='black', linestyle='dashed', linewidth=2, label=f'Topic {topic} Mean: {mean_score:.2f}')\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel('VADER Sentiment Compound Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Sentiment of Topic {topic} (n = {len(compound_topic)})')\n",
    "    \n",
    "    # Show legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n"
   ],
   "id": "6e5bd053ea78d965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Statistics by Topic",
   "id": "ca333c7cab920791"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "general_log",
   "id": "c7db6cb97c0d1166",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sentiment_stats_by_topic(data, topic_val):\n",
    "    df = data[data[\"topic_final\"] == topic_val]\n",
    "    total = len(df)\n",
    "\n",
    "    if total == 0:\n",
    "        sentiment_result = {k: (\"No data\", 0, [None, None]) for k in ['negative', 'neutral', 'positive']}\n",
    "        return 0, sentiment_result, (\"No data\", [None, None])\n",
    "\n",
    "    # Sentiment distribution\n",
    "    sentiment_result = {}\n",
    "    for group in [\"negative\", \"neutral\", \"positive\"]:\n",
    "        count = df[df[\"post_group\"] == group].shape[0]\n",
    "        p = count / total\n",
    "        se = np.sqrt(p * (1 - p) / total)\n",
    "        ci = [p - 1.96 * se, p + 1.96 * se]\n",
    "        sentiment_result[group] = (count, round(p * 100, 2), [round(ci[0] * 100, 2), round(ci[1] * 100, 2)])\n",
    "\n",
    "    # Compound score mean and 95% CI\n",
    "    compound_scores = df[\"compounds_score\"].dropna()\n",
    "    n = len(compound_scores)\n",
    "    if n == 0:\n",
    "        compound_result = (\"No data\", [None, None])\n",
    "    else:\n",
    "        mean = compound_scores.mean()\n",
    "        se = compound_scores.std(ddof=1) / np.sqrt(n)\n",
    "        ci = [mean - 1.96 * se, mean + 1.96 * se]\n",
    "        compound_result = (round(mean, 3), [round(ci[0], 3), round(ci[1], 3)])\n",
    "\n",
    "    return total, sentiment_result, compound_result\n",
    "\n",
    "# Loop through topics\n",
    "for topic in sorted(general_log[\"topic_final\"].dropna().unique()):\n",
    "    total, sentiment_data, compound_data = sentiment_stats_by_topic(general_log, topic)\n",
    "    \n",
    "    print(f\"Topic: {int(topic)} (Total posts: {total})\\n\")\n",
    "    print(\"Sentiment Breakdown:\")\n",
    "    for sentiment, (count, prop, ci) in sentiment_data.items():\n",
    "        if prop == \"No data\":\n",
    "            print(f\"  {sentiment.capitalize()}: No data\")\n",
    "        else:\n",
    "            print(f\"  {sentiment.capitalize()}: {count} posts {prop}% (95% CI: [{ci[0]}%, {ci[1]}%])\")\n",
    "    \n",
    "    if compound_data[0] == \"No data\":\n",
    "        print(\"\\nMean Compound Score: No data\")\n",
    "    else:\n",
    "        mean, ci = compound_data\n",
    "        print(f\"\\nMean Compound Score: {mean}\")\n",
    "        print(f\"  (95% CI, [{ci[0]}, {ci[1]}])\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ],
   "id": "863d13a4763fb5fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def overall_sentiment_and_compound(data):\n",
    "    total = len(data)\n",
    "\n",
    "    # Sentiment stats\n",
    "    sentiment_result = {}\n",
    "    for group in [\"negative\", \"neutral\", \"positive\"]:\n",
    "        count = data[data[\"post_group\"] == group].shape[0]\n",
    "        p = count / total\n",
    "        se = np.sqrt(p * (1 - p) / total)\n",
    "        ci = [p - 1.96 * se, p + 1.96 * se]\n",
    "        sentiment_result[group] = (count, round(p * 100, 2), [round(ci[0] * 100, 2), round(ci[1] * 100, 2)])\n",
    "\n",
    "    # Compound score mean and 95% CI\n",
    "    compound_scores = data[\"compounds_score\"].dropna()\n",
    "    n = len(compound_scores)\n",
    "    mean = compound_scores.mean()\n",
    "    se = compound_scores.std(ddof=1) / np.sqrt(n)\n",
    "    ci = [mean - 1.96 * se, mean + 1.96 * se]\n",
    "    compound_result = (round(mean, 3), [round(ci[0], 3), round(ci[1], 3)])\n",
    "\n",
    "    return total, sentiment_result, compound_result\n",
    "\n",
    "# Run it on your full DataFrame\n",
    "total, sentiment_data, compound_data = overall_sentiment_and_compound(general_log)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total posts: {total}\\n\")\n",
    "print(\"Sentiment Breakdown:\")\n",
    "for sentiment, (count, percent, ci) in sentiment_data.items():\n",
    "    print(f\"  {sentiment.capitalize()}: {count} posts ({percent}%, 95% CI: [{ci[0]}%, {ci[1]}%])\")\n",
    "\n",
    "mean, mean_ci = compound_data\n",
    "print(f\"\\nMean Compound Score: {mean}\")\n",
    "print(f\"95% CI of Mean: [{mean_ci[0]}, {mean_ci[1]}]\")"
   ],
   "id": "70d425ee1190c368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### statistics by keyword regardless of topic number",
   "id": "61e0fc608be4952f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def proportion_with_ci(data, keyword):\n",
    "    df = data[data[\"keyword\"] == keyword]\n",
    "    total = len(df)\n",
    "    \n",
    "    if total == 0:\n",
    "        return {k: (\"No data\", 0, [None, None]) for k in ['negative', 'neutral', 'positive']}\n",
    "    \n",
    "    result = {}\n",
    "    for group in [\"negative\", \"neutral\", \"positive\"]:\n",
    "        count = df[df[\"post_group\"] == group].shape[0]\n",
    "        p = count / total\n",
    "        se = np.sqrt(p * (1 - p) / total)\n",
    "        ci = [p - 1.96 * se, p + 1.96 * se]\n",
    "        # Convert to percentage\n",
    "        result[group] = (count, round(p * 100, 2), [round(ci[0] * 100, 2), round(ci[1] * 100, 2)])\n",
    "    \n",
    "    return result\n",
    "\n",
    "keywords = [\n",
    "    \"on! pouches\", \"rogue pouches\", \"zyn\", \"Lucy pouches\", \"unspecified\",\n",
    "    \"fre pouches\", \"velo pouches\", \"niin pouches\", \"fr3sh pouches\"\n",
    "]\n",
    "\n",
    "for kw in keywords:\n",
    "    print(f\"Keyword: {kw}\")\n",
    "    res = proportion_with_ci(general_log, kw)\n",
    "    for sentiment, (count, prop, ci) in res.items():\n",
    "        if prop == \"No data\":\n",
    "            print(f\"  {sentiment.capitalize()}: No data\")\n",
    "        else:\n",
    "            print(f\"  {sentiment.capitalize()}: {count} posts ({prop}%, 95% CI, [{ci[0]}%, {ci[1]}%])\")\n",
    "    print()"
   ],
   "id": "a4ab36af27cc7bdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def overall_sentiment_summary(data):\n",
    "    total = len(data)\n",
    "    result = {}\n",
    "\n",
    "    for group in [\"negative\", \"neutral\", \"positive\"]:\n",
    "        count = data[data[\"post_group\"] == group].shape[0]\n",
    "        p = count / total\n",
    "        se = np.sqrt(p * (1 - p) / total)\n",
    "        ci = [p - 1.96 * se, p + 1.96 * se]\n",
    "        result[group] = (count, round(p * 100, 2), [round(ci[0] * 100, 2), round(ci[1] * 100, 2)])\n",
    "    \n",
    "    return total, result\n",
    "\n",
    "# Run it\n",
    "total_posts, sentiment_breakdown = overall_sentiment_summary(general_log)\n",
    "\n",
    "print(f\"Total posts: {total_posts}\\n\")\n",
    "for sentiment, (count, percentage, ci) in sentiment_breakdown.items():\n",
    "    print(f\"{sentiment.capitalize()}: {count} posts ({percentage}%, (95% CI, [{ci[0]}%, {ci[1]}%])\")"
   ],
   "id": "22c3a8afd94379e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    data = np.array(data.dropna())\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    stderr = stats.sem(data)  # standard error\n",
    "    margin = stderr * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "    return mean, mean - margin, mean + margin\n",
    "keywords = [\n",
    "    \"on! pouches\", \"rogue pouches\", \"zyn\", \"Lucy pouches\",\n",
    "    \"unspecified\", \"fre pouches\", \"velo pouches\", \"niin pouches\", \"fr3sh pouches\"\n",
    "]\n",
    "\n",
    "for keyword in keywords:\n",
    "    scores = general_log[general_log[\"keyword\"] == keyword][\"compounds_score\"]\n",
    "    mean, lower, upper = mean_confidence_interval(scores)\n",
    "    print(f\"{keyword:<15} | Mean: {mean:.4f} | 95% CI: ({lower:.4f}, {upper:.4f})\")"
   ],
   "id": "1e236b4ed1753e76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "output",
   "id": "e21f22a19727e1fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output = general_log\n",
    "output.head()"
   ],
   "id": "3753e8fd1e9d58c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output.drop(\"topics\", axis = 1)",
   "id": "d829d2a1093ba41b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output.to_csv('reddit_combined_final.csv', index=False)",
   "id": "f0971e9547037a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('reddit_combined_final.csv')"
   ],
   "id": "adb3af53f88d6232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'time_posted' to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time_posted'])\n",
    "\n",
    "# Set 'timestamp' as the index\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Resample by week (average sentiment per week)\n",
    "weekly_sentiment = df['compounds_score'].resample('W').mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(weekly_sentiment.index, weekly_sentiment, marker='o', linestyle='-')\n",
    "plt.title('Weekly Average Sentiment Over Time')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "a0aa2b717c0d4b75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'time_posted' to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time_posted'])\n",
    "\n",
    "# Set 'timestamp' as index\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Resample by month and calculate average sentiment\n",
    "monthly_sentiment = df['compounds_score'].resample('M').mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_sentiment.index, monthly_sentiment, marker='o', linestyle='-')\n",
    "plt.title('Monthly Average Sentiment Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.grid\n"
   ],
   "id": "a17120e29eb3f28f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert 'time_posted' to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time_posted'])\n",
    "\n",
    "# Set 'timestamp' as index\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Resample by year and calculate average sentiment\n",
    "yearly_sentiment = df['compounds_score'].resample('Y').mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(yearly_sentiment.index, yearly_sentiment, marker='o', linestyle='-')\n",
    "plt.title('Yearly Average Sentiment Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.grid(True)\n",
    "\n",
    "# Optional: Format x-axis to show year only\n",
    "import matplotlib.dates as mdates\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "5b80c757a53b097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Graphs",
   "id": "72a41acfcf6cb0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('reddit_combined_final.csv')\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"zyn\", \"ZYN\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"Lucy pouches\", \"Lucy\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"fr3sh pouches\", \"FR3SH\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"niin pouches\", \"NIIN\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"on! pouches\", \"on!\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"rogue pouches\", \"Rogue\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"fre pouches\", \"FRE\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"velo pouches\", \"VELO\")\n",
    "df[\"keyword\"] = df[\"keyword\"].replace(\"unspecified\", \"Others\")"
   ],
   "id": "6a275cecd0570aa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Choose the keyword order you want to appear in the legend\n",
    "#     (edit or reorder this list as you like)\n",
    "# ------------------------------------------------------------------\n",
    "keywords = [\n",
    "    \"VELO\",\n",
    "    'on!',\n",
    "    'ZYN',\n",
    "    'Others',\n",
    "    'FRE',\n",
    "    'Lucy',\n",
    "    'FR3SH',\n",
    "    'NIIN',\n",
    "    'Rogue'\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Colour-blind-friendly palette (close to seaborn-colorblind)\n",
    "# ------------------------------------------------------------------\n",
    "palette = [\n",
    "    '#0173b2',  # blue\n",
    "    '#de8f05',  # orange\n",
    "    '#029e73',  # green\n",
    "    '#d55e00',  # red-orange\n",
    "    '#cc78bc',  # purple\n",
    "    '#ca9161',  # brown\n",
    "    '#fbafe4',  # pink\n",
    "    '#949494',  # gray\n",
    "    '#ece133'   # yellow-green\n",
    "]\n",
    "colour_map = dict(zip(keywords, palette))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Plot the filled KDEs\n",
    "# ------------------------------------------------------------------\n",
    "# (White background is the default Matplotlib style, so we *don't* call\n",
    "#  plt.style.use('dark_background') here.)\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "x_grid = np.linspace(-1, 1, 400)     # evaluation grid for all KDEs\n",
    "\n",
    "for kw in keywords:\n",
    "    scores = df.loc[df['keyword'] == kw, 'compounds_score'].dropna()\n",
    "    if len(scores) > 1:               # need at least 2 points for a KDE\n",
    "        kde = gaussian_kde(scores)\n",
    "        y = kde.evaluate(x_grid)\n",
    "        c = colour_map[kw]\n",
    "        plt.fill_between(x_grid, y, alpha=0.35, color=c)   # semi-transparent fill\n",
    "        plt.plot(x_grid, y, linewidth=1, color=c, \n",
    "                 label=f'{kw} (n={len(scores)})')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  Cosmetic touches\n",
    "# ------------------------------------------------------------------\n",
    "plt.xlabel('Compound Sentiment Score')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.legend(title='Keyword', bbox_to_anchor=(1.02, 1), loc='upper left',\n",
    "           fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "474660549b730abd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "4b1edb283ca28531"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from math import ceil, sqrt\n",
    "\n",
    "# ── 0.  Global font ───────────────────────────────────────────────\n",
    "plt.rcParams[\"font.family\"] = \"Spectral\"\n",
    "\n",
    "# === Controls: shrink circle & enlarge text ======================\n",
    "RADIUS_SCALE     = 0.75   # < 1.0 makes the radar circle smaller (no clipping)\n",
    "LABEL_FONTSIZE   = 10     # keyword label size (was 8)\n",
    "TITLE_FONTSIZE_AX= 13     # per-axes title size (was 11)\n",
    "TITLE_FONTSIZE_FG= 16     # figure-level title size (was 14)\n",
    "XTICK_PAD        = 14     # extra space between circle and labels\n",
    "LINEWIDTH        = 2.2    # a touch thicker for visibility\n",
    "FILL_ALPHA       = 0.25\n",
    "\n",
    "# ── 1.  Load data ────────────────────────────────────────────────\n",
    "for col in (\"keyword\", \"compounds_score\", \"topic_final\"):\n",
    "    if col not in df.columns:\n",
    "        raise RuntimeError(f\"Missing column: {col}\")\n",
    "\n",
    "# ── 2.  Fixed spokes (overall top-8 keywords) ────────────────────\n",
    "top8   = df[\"keyword\"].value_counts().head(8).index.tolist()\n",
    "angles = np.linspace(0, 2*np.pi, len(top8), endpoint=False).tolist() + [0]\n",
    "\n",
    "# ── 3.  Colour palette ───────────────────────────────────────────\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# ── 4.  Helper: radar of **counts** (labels include %) ────────────\n",
    "def radar_topic(ax, topic_df, title, colour):\n",
    "    counts = topic_df[\"keyword\"].value_counts().reindex(top8, fill_value=0)\n",
    "    props  = (counts / counts.sum()).fillna(0)\n",
    "    mx     = counts.max() or 1\n",
    "\n",
    "    # scale to 0–1 then shrink by RADIUS_SCALE so the circle is smaller\n",
    "    base_scaled = (counts / mx).tolist() + [(counts / mx).iloc[0]]\n",
    "    scaled = [v * RADIUS_SCALE for v in base_scaled]\n",
    "\n",
    "    # plot\n",
    "    ax.plot(angles, scaled, linewidth=LINEWIDTH, color=colour)\n",
    "    ax.fill(angles, scaled, alpha=FILL_ALPHA, color=colour)\n",
    "\n",
    "    # ticks & labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(\n",
    "        [f\"{kw}\\n({counts[kw]} , {props[kw]:.1%})\" for kw in top8],\n",
    "        fontsize=LABEL_FONTSIZE, fontfamily=\"Spectral\"\n",
    "    )\n",
    "    ax.tick_params(axis=\"x\", pad=XTICK_PAD)  # push labels outward\n",
    "\n",
    "    # radius limits match the scaled max to avoid clipping and keep ring small\n",
    "    ax.set_ylim(0, RADIUS_SCALE)\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # styling\n",
    "    ax.set_title(title, pad=16, fontsize=TITLE_FONTSIZE_AX, fontfamily=\"Spectral\", fontweight=\"bold\")\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.spines[\"polar\"].set_color(\"#888\")\n",
    "    ax.grid(color=\"#bbb\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# ── 5.  Layout and per-topic colours ─────────────────────────────\n",
    "topics = sorted(df[\"topic_final\"].dropna().unique())\n",
    "\n",
    "# Build colour map from tab10 …\n",
    "colour_map = {tp: cmap(i % cmap.N) for i, tp in enumerate(topics)}\n",
    "# … then override Topic 1 (if it exists) to be a bold red\n",
    "if 1 in colour_map:\n",
    "    colour_map[1] = \"tab:red\"\n",
    "elif topics:\n",
    "    colour_map[topics[0]] = \"tab:red\"\n",
    "\n",
    "n_topics = len(topics)\n",
    "\n",
    "if n_topics == 3:\n",
    "    # slightly larger figure so big labels breathe\n",
    "    fig = plt.figure(figsize=(11, 11), facecolor=\"white\")\n",
    "    gs  = matplotlib.gridspec.GridSpec(2, 2, height_ratios=[1, 1])\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, :], polar=True)\n",
    "    ax2 = fig.add_subplot(gs[1, 0], polar=True)\n",
    "    ax3 = fig.add_subplot(gs[1, 1], polar=True)\n",
    "\n",
    "    radar_topic(ax1, df[df[\"topic_final\"] == topics[0]], f\"Topic {topics[0]}\", colour_map[topics[0]])\n",
    "    radar_topic(ax2, df[df[\"topic_final\"] == topics[1]], f\"Topic {topics[1]}\", colour_map[topics[1]])\n",
    "    radar_topic(ax3, df[df[\"topic_final\"] == topics[2]], f\"Topic {topics[2]}\", colour_map[topics[2]])\n",
    "else:\n",
    "    n_cols = ceil(sqrt(n_topics))\n",
    "    n_rows = ceil(n_topics / n_cols)\n",
    "    # scale per-subplot size up a bit to fit larger labels\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols,\n",
    "        figsize=(n_cols*4.8, n_rows*4.8),\n",
    "        subplot_kw=dict(polar=True),\n",
    "        facecolor=\"white\"\n",
    "    )\n",
    "    axes = np.atleast_1d(axes).flatten()\n",
    "\n",
    "    for ax, tp in zip(axes, topics):\n",
    "        radar_topic(ax, df[df[\"topic_final\"] == tp], f\"Topic {tp}\", colour_map[tp])\n",
    "    for ax in axes[n_topics:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "# ── 6.  Figure-level title & layout tweaks ───────────────────────\n",
    "fig.suptitle(\n",
    "    \"Keyword Post Counts & Proportions by Topic\",\n",
    "    y=0.98, fontsize=TITLE_FONTSIZE_FG, fontweight=\"bold\",\n",
    "    fontfamily=\"Spectral\", color=\"black\"\n",
    ")\n",
    "\n",
    "# leave a bit more room for the bigger labels\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ],
   "id": "59c26be57293ebde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ── 0.  Global font ───────────────────────────────────────────────\n",
    "plt.rcParams[\"font.family\"] = \"Spectral\"\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "# ── 1.  Load data ────────────────────────────────────────────────\n",
    "if \"keyword\" not in df.columns:\n",
    "    raise RuntimeError(\"Missing 'keyword' column\")\n",
    "\n",
    "# ── 2.  Overall top-8 keywords (fixed spoke order) ───────────────\n",
    "top8   = df[\"keyword\"].value_counts().head(8).index.tolist()\n",
    "angles = np.linspace(0, 2*np.pi, len(top8), endpoint=False).tolist() + [0]  # close loop\n",
    "\n",
    "# ── 3.  Counts + proportions → 0–1 scaling for radius ────────────\n",
    "counts = df[\"keyword\"].value_counts().reindex(top8, fill_value=0)\n",
    "props  = counts / counts.sum()\n",
    "scaled = (counts / counts.max()).tolist() + [(counts / counts.max()).iloc[0]]\n",
    "\n",
    "# ── 4.  Plot ─────────────────────────────────────────────────────\n",
    "fig = plt.figure(figsize=(8, 8), facecolor=\"white\")\n",
    "ax  = plt.subplot(111, polar=True)\n",
    "\n",
    "# Make the circle smaller (more space for text)\n",
    "ax.set_position([0.15, 0.15, 0.7, 0.7])  # [left, bottom, width, height]\n",
    "ax.set_rmax(0.8)                          # shrink radial extent\n",
    "\n",
    "# Plot lines and fill\n",
    "ax.plot(angles, scaled, linewidth=2.5, color=\"#1f77b4\")\n",
    "ax.fill(angles, scaled, alpha=0.25, color=\"#1f77b4\")\n",
    "\n",
    "# Labels: \"keyword \\n(count • pct)\"\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(\n",
    "    [f\"{kw}\\n({counts[kw]} , {props[kw]:.1%})\" for kw in top8],\n",
    "    fontsize=16,             # larger label font\n",
    "    fontfamily=\"Spectral\",\n",
    ")\n",
    "\n",
    "# Cleanup\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.spines[\"polar\"].set_color(\"#888\")\n",
    "ax.grid(color=\"#bbbbbb\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# Title\n",
    "ax.set_title(\n",
    "    \"Overall Keyword Post Counts & Proportions (linear-scaled radar)\",\n",
    "    pad=40,\n",
    "    fontsize=14,\n",
    "    fontfamily=\"Spectral\",\n",
    "    fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "240681be991f2cae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "see if the topics are different",
   "id": "4b692e7dae4333a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df = pd.read_csv(\"reddit_combined_final.csv\")\n",
    "df = df.dropna(subset=[\"topic_final\", \"compounds_score\"])\n",
    "groups = df[\"topic_final\"].unique()\n",
    "results = []\n",
    "for g1, g2 in combinations(groups, 2):\n",
    "    scores1 = df[df[\"topic_final\"] == g1][\"compounds_score\"]\n",
    "    scores2 = df[df[\"topic_final\"] == g2][\"compounds_score\"]\n",
    "    \n",
    "    # Welch's t-test (doesn't assume equal variances)\n",
    "    t_stat, p_val = ttest_ind(scores1, scores2, equal_var=False)\n",
    "    \n",
    "    results.append((g1, g2, t_stat, p_val))\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\"Group 1\", \"Group 2\", \"t-statistic\", \"p-value\"])\n",
    "\n",
    "# Optional: Bonferroni correction for multiple comparisons\n",
    "results_df[\"p-adjusted (Bonferroni)\"] = multipletests(results_df[\"p-value\"], method=\"bonferroni\")[1]\n",
    "\n",
    "# Display results\n",
    "print(results_df)\n"
   ],
   "id": "fae25f32407ad32c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
